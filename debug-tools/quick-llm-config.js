// å¿«é€Ÿé…ç½®LLMçš„è„šæœ¬
console.log("âš™ï¸ å¿«é€ŸLLMé…ç½®å·¥å…·");

async function quickLLMConfig() {
  console.log("ğŸ”§ å¼€å§‹å¿«é€Ÿé…ç½®LLM...");
  
  // å¸¸è§çš„LLMé…ç½®é€‰é¡¹
  const commonConfigs = {
    "æœ¬åœ°LM Studio": {
      provider: "custom",
      endpoint: "http://localhost:1234/v1/chat/completions",
      apiKey: "",
      model: "local-model"
    },
    "æœ¬åœ°Ollama": {
      provider: "custom", 
      endpoint: "http://localhost:11434/v1/chat/completions",
      apiKey: "",
      model: "llama2"
    },
    "OpenAI": {
      provider: "openai",
      endpoint: "https://api.openai.com/v1/chat/completions",
      apiKey: "your-openai-api-key",
      model: "gpt-3.5-turbo"
    },
    "è‡ªå®šä¹‰": {
      provider: "custom",
      endpoint: "http://your-endpoint/v1/chat/completions",
      apiKey: "your-api-key",
      model: "your-model"
    }
  };
  
  console.log("ğŸ“‹ å¯ç”¨é…ç½®é€‰é¡¹:");
  Object.keys(commonConfigs).forEach((name, index) => {
    const config = commonConfigs[name];
    console.log(`${index + 1}. ${name}:`);
    console.log(`   Endpoint: ${config.endpoint}`);
    console.log(`   Model: ${config.model}`);
    console.log(`   éœ€è¦API Key: ${config.apiKey ? 'æ˜¯' : 'å¦'}`);
  });
  
  // æ£€æŸ¥å½“å‰é…ç½®
  try {
    const result = await chrome.storage.sync.get(['llmConfig']);
    const currentConfig = result.llmConfig || {};
    
    console.log("\nğŸ“Š å½“å‰é…ç½®:", currentConfig);
    
    if (!currentConfig.endpoint) {
      console.log("\nâš ï¸ æœªæ£€æµ‹åˆ°LLMé…ç½®ï¼Œå»ºè®®ä½¿ç”¨ä»¥ä¸‹é…ç½®:");
      
      const recommendedConfig = commonConfigs["æœ¬åœ°LM Studio"];
      console.log("ğŸ¯ æ¨èé…ç½® (æœ¬åœ°LM Studio):");
      console.log("   é€‚åˆæœ¬åœ°å¼€å‘å’Œæµ‹è¯•");
      console.log("   ä¸éœ€è¦APIå¯†é’¥");
      console.log("   é…ç½®:", JSON.stringify(recommendedConfig, null, 2));
      
      // è‡ªåŠ¨åº”ç”¨æ¨èé…ç½®
      console.log("\nğŸ”„ è‡ªåŠ¨åº”ç”¨æ¨èé…ç½®...");
      await chrome.storage.sync.set({ llmConfig: recommendedConfig });
      console.log("âœ… é…ç½®å·²ä¿å­˜");
      
      // æµ‹è¯•é…ç½®
      console.log("ğŸ” æµ‹è¯•æ–°é…ç½®...");
      try {
        const testResult = await chrome.runtime.sendMessage({
          action: "testLLMConnection",
          data: recommendedConfig
        });
        
        if (testResult.success) {
          console.log("âœ… é…ç½®æµ‹è¯•æˆåŠŸ:", testResult.message);
          console.log("ğŸ‰ LLMé…ç½®å®Œæˆï¼Œç°åœ¨å¯ä»¥ä½¿ç”¨åˆ†æåŠŸèƒ½äº†ï¼");
        } else {
          console.log("âŒ é…ç½®æµ‹è¯•å¤±è´¥:", testResult.error);
          console.log("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:");
          console.log("   1. ç¡®ä¿LM Studioæ­£åœ¨è¿è¡Œå¹¶ç›‘å¬1234ç«¯å£");
          console.log("   2. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®");
          console.log("   3. å°è¯•å…¶ä»–é…ç½®é€‰é¡¹");
        }
      } catch (testError) {
        console.log("âŒ æµ‹è¯•é…ç½®æ—¶å‡ºé”™:", testError);
      }
      
    } else {
      console.log("âœ… å·²æœ‰LLMé…ç½®");
      
      // æµ‹è¯•ç°æœ‰é…ç½®
      console.log("ğŸ” æµ‹è¯•ç°æœ‰é…ç½®...");
      try {
        const testResult = await chrome.runtime.sendMessage({
          action: "testLLMConnection", 
          data: currentConfig
        });
        
        if (testResult.success) {
          console.log("âœ… ç°æœ‰é…ç½®å·¥ä½œæ­£å¸¸:", testResult.message);
        } else {
          console.log("âŒ ç°æœ‰é…ç½®æœ‰é—®é¢˜:", testResult.error);
          console.log("ğŸ’¡ å»ºè®®é‡æ–°é…ç½®æˆ–æ£€æŸ¥æœåŠ¡çŠ¶æ€");
        }
      } catch (testError) {
        console.log("âŒ æµ‹è¯•ç°æœ‰é…ç½®æ—¶å‡ºé”™:", testError);
      }
    }
    
  } catch (error) {
    console.error("âŒ é…ç½®è¿‡ç¨‹å‡ºé”™:", error);
  }
}

// æ‰‹åŠ¨è®¾ç½®é…ç½®çš„å‡½æ•°
window.setLLMConfig = async function(configName) {
  const configs = {
    "lmstudio": {
      provider: "custom",
      endpoint: "http://localhost:1234/v1/chat/completions",
      apiKey: "",
      model: "local-model"
    },
    "ollama": {
      provider: "custom",
      endpoint: "http://localhost:11434/v1/chat/completions", 
      apiKey: "",
      model: "llama2"
    }
  };
  
  const config = configs[configName];
  if (config) {
    await chrome.storage.sync.set({ llmConfig: config });
    console.log("âœ… é…ç½®å·²è®¾ç½®:", config);
    
    // æµ‹è¯•é…ç½®
    const testResult = await chrome.runtime.sendMessage({
      action: "testLLMConnection",
      data: config
    });
    console.log("æµ‹è¯•ç»“æœ:", testResult);
  } else {
    console.log("âŒ æœªçŸ¥é…ç½®åç§°ï¼Œå¯ç”¨é€‰é¡¹: lmstudio, ollama");
  }
};

// è¿è¡Œå¿«é€Ÿé…ç½®
quickLLMConfig();

console.log("\nğŸ’¡ ä½¿ç”¨æç¤º:");
console.log("å¦‚éœ€æ‰‹åŠ¨è®¾ç½®é…ç½®ï¼Œå¯ä»¥è¿è¡Œ:");
console.log("  setLLMConfig('lmstudio')  // è®¾ç½®LM Studioé…ç½®");
console.log("  setLLMConfig('ollama')    // è®¾ç½®Ollamaé…ç½®");